{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Problem 5</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Object Detection with YOLO - Documentation</h1>\n",
    "    <p>Below is the documentation for the Python script using the Ultralytics YOLO library to perform object detection on images in a specified folder:</p>\n",
    "    \n",
    "<h2>Code Overview</h2>\n",
    "<ol>\n",
    "    <li>Import necessary libraries including <code>os</code>, <code>shutil</code>, <code>itertools</code>, <code>matplotlib.pyplot</code>, <code>YOLO</code> from Ultralytics, and <code>clip</code> from OpenAI.</li>\n",
    "    <li>Define the function <code>detect_and_save_objects(yolo_model, input_folder, output_folder)</code> to perform object detection on images and save detected object crops.</li>\n",
    "    <li>Define the function <code>compare_images_using_clip(clip_model, output_folder)</code> to compare images using the CLIP model and save similar object crops.</li>\n",
    "    <li>Define the main function <code>main()</code> to orchestrate the execution of object detection and image comparison.</li>\n",
    "    <li>Call the <code>main()</code> function when the script is run as the main module.</li>\n",
    "</ol>\n",
    "\n",
    "<h2>Execution Flow</h2>\n",
    "<ol>\n",
    "    <li>Create a YOLO model instance using the pretrained model file <code>yolov8m.pt</code>.</li>\n",
    "    <li>Specify input and output directories for images and results.</li>\n",
    "    <li>Call the <code>detect_and_save_objects</code> function to perform object detection and save object crops.</li>\n",
    "    <li>Call the <code>compare_images_using_clip</code> function to compare images and save similar object crops.</li>\n",
    "</ol>\n",
    "\n",
    "<h2>Main Execution</h2>\n",
    "<ul>\n",
    "    <li>Check if the script is being run as the main module using <code>if __name__ == \"__main__\":</code></li>\n",
    "    <li>Call the <code>main()</code> function to initiate the execution of object detection and comparison.</li>\n",
    "    <li>Handle exceptions and print error messages in case of failures.</li>\n",
    "</ul>\n",
    "    \n",
    "<p>This documentation provides an overview of the code's functionality and execution process.</p>\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\1.jpg: 384x640 4 persons, 1 couch, 2 potted plants, 1 vase, 1145.2ms\n",
      "Speed: 8.5ms preprocess, 1145.2ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\2.jpg: 448x640 2 persons, 1 tie, 1 bed, 1 cell phone, 1153.7ms\n",
      "Speed: 7.0ms preprocess, 1153.7ms inference, 31.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\3.jpg: 448x640 4 persons, 1 sports ball, 1278.9ms\n",
      "Speed: 7.0ms preprocess, 1278.9ms inference, 5.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_112814949.jpeg: 448x640 1 spoon, 1 bowl, 1 sandwich, 1 dining table, 1214.5ms\n",
      "Speed: 14.6ms preprocess, 1214.5ms inference, 3.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_119085612.jpeg: 480x640 1 cup, 1 toothbrush, 1160.3ms\n",
      "Speed: 6.5ms preprocess, 1160.3ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_189740072.jpeg: 448x640 1 person, 2 benchs, 1 handbag, 1 suitcase, 1279.4ms\n",
      "Speed: 6.9ms preprocess, 1279.4ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_254640691.jpeg: 448x640 1 spoon, 4 bowls, 2 broccolis, 2 dining tables, 1016.1ms\n",
      "Speed: 5.0ms preprocess, 1016.1ms inference, 7.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_255497590.jpeg: 352x640 1 person, 1 bowl, 1 sandwich, 1 dining table, 1134.2ms\n",
      "Speed: 8.8ms preprocess, 1134.2ms inference, 5.5ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_257024669.jpeg: 448x640 1 suitcase, 1 cell phone, 1 clock, 1258.9ms\n",
      "Speed: 7.2ms preprocess, 1258.9ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_286178925.jpeg: 448x640 5 bowls, 2 sandwichs, 3 pizzas, 8 donuts, 1059.7ms\n",
      "Speed: 5.2ms preprocess, 1059.7ms inference, 5.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_297274410.jpeg: 448x640 2 persons, 1 spoon, 2 bowls, 1 chair, 3 dining tables, 979.7ms\n",
      "Speed: 3.0ms preprocess, 979.7ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_315333860.jpeg: 448x640 5 persons, 1 wine glass, 3 cups, 2 forks, 2 knifes, 1 bowl, 5 pizzas, 1 dining table, 971.2ms\n",
      "Speed: 5.0ms preprocess, 971.2ms inference, 4.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_321810820.jpeg: 384x640 6 persons, 1 boat, 1 backpack, 832.6ms\n",
      "Speed: 3.4ms preprocess, 832.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_323628715.jpeg: 448x640 5 persons, 4 cups, 1 spoon, 1 bowl, 4 pizzas, 1 dining table, 1226.9ms\n",
      "Speed: 6.6ms preprocess, 1226.9ms inference, 5.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_349162891.jpeg: 608x640 1 sandwich, 1517.0ms\n",
      "Speed: 8.4ms preprocess, 1517.0ms inference, 4.0ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_425653713.jpeg: 448x640 1 suitcase, 1 potted plant, 1 laptop, 1055.8ms\n",
      "Speed: 8.1ms preprocess, 1055.8ms inference, 3.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_57849082.jpeg: 448x640 1 person, 1 fork, 2 pizzas, 1 dining table, 1135.1ms\n",
      "Speed: 6.2ms preprocess, 1135.1ms inference, 3.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_58143201.jpeg: 480x640 2 toothbrushs, 1354.2ms\n",
      "Speed: 5.0ms preprocess, 1354.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_584637362.jpeg: 448x640 2 airplanes, 2 suitcases, 1093.1ms\n",
      "Speed: 8.6ms preprocess, 1093.1ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_594853635.jpeg: 224x640 4 sandwichs, 639.1ms\n",
      "Speed: 3.5ms preprocess, 639.1ms inference, 6.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "\n",
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_608957878.jpeg: 448x640 2 persons, 2 toothbrushs, 1076.3ms\n",
      "Speed: 6.8ms preprocess, 1076.3ms inference, 3.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_618914535.jpeg: 480x640 2 sandwichs, 1048.8ms\n",
      "Speed: 4.2ms preprocess, 1048.8ms inference, 6.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_92669497.jpeg: 448x640 8 persons, 2 suitcases, 971.2ms\n",
      "Speed: 4.5ms preprocess, 971.2ms inference, 5.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\AdobeStock_96284524.jpeg: 448x640 12 donuts, 1 dining table, 1121.0ms\n",
      "Speed: 5.6ms preprocess, 1121.0ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\DL.jpeg: 384x640 1 bottle, 992.8ms\n",
      "Speed: 3.6ms preprocess, 992.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\maxresdefault.jpeg: 384x640 2 persons, 1 bottle, 993.2ms\n",
      "Speed: 5.1ms preprocess, 993.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 d:\\Adobe\\Aithon\\Aithon\\All_Images\\Mist.jpeg: 448x640 1 bottle, 1012.4ms\n",
      "Speed: 5.1ms preprocess, 1012.4ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred during image comparison: Unexpected type <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import clip\n",
    "\n",
    "\n",
    "# Function to perform YOLO object detection and save cropped images\n",
    "def detect_and_save_objects(yolo_model, input_folder, output_folder):\n",
    "    try:\n",
    "        # Get YOLO detections function from the model\n",
    "        \n",
    "        # Get a list of image paths in the input folder\n",
    "        image_paths = [os.path.join(input_folder, img) for img in os.listdir(input_folder) if img.lower().endswith(('.jpeg', '.jpg'))]\n",
    "\n",
    "        for img_path in image_paths:\n",
    "            # Extract image name without extension\n",
    "            image_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            # Create output folder for the image's detections\n",
    "            output_img_folder = os.path.join(output_folder, image_name)\n",
    "            os.makedirs(output_img_folder, exist_ok=True)\n",
    "\n",
    "            # Perform object detection using YOLO\n",
    "            detected_objects = yolo_model.predict(img_path, save=False)\n",
    "            object_counts = {}  # Track counts of different objects in the image\n",
    "\n",
    "            for idx, detected_obj in enumerate(detected_objects[0].boxes):\n",
    "                obj_class = detected_obj.cls[0].item()\n",
    "                object_counts[obj_class] = object_counts.get(obj_class, 0) + 1\n",
    "\n",
    "                class_label = detected_objects[0].names[obj_class]\n",
    "                entity_folder = os.path.join(output_img_folder, f\"{class_label}_{object_counts[obj_class]}\")\n",
    "                os.makedirs(entity_folder, exist_ok=True)\n",
    "\n",
    "                # Extract object's bounding box coordinates\n",
    "                x_min, y_min, x_max, y_max = detected_obj.xyxy[0]\n",
    "                x_min, y_min, x_max, y_max = int(x_min), int(y_min), int(x_max), int(y_max)\n",
    "\n",
    "                # Crop the object from the image\n",
    "                cutout = plt.imread(img_path)[y_min:y_max, x_min:x_max]\n",
    "                output_filename = f\"{class_label}_{object_counts[obj_class]}_crop.jpg\"\n",
    "                plt.imsave(os.path.join(entity_folder, output_filename), cutout)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Error occurred during object detection and saving:\", e)\n",
    "\n",
    "# Function to compare images using the CLIP model\n",
    "def compare_images_using_clip(clip_model, output_folder):\n",
    "    try:\n",
    "        # Load CLIP model and preprocessing function\n",
    "        clip_model, clip_preprocess = clip_model.load(\"ViT-B/32\")\n",
    "        # Get matched image paths for CLIP comparison\n",
    "        matched_image_paths = [os.path.join(root, file) for root, _, files in os.walk(output_folder) for file in files if file.endswith('.jpg')]\n",
    "\n",
    "        for root, _, files in os.walk(output_folder):\n",
    "            if files:\n",
    "                # Get the path of the reference image for comparison\n",
    "                reference_img_path = os.path.join(root, files[0])\n",
    "                reference_entity = ''.join(filter(lambda z: not z.isdigit(), files[0].split('_')[0]))\n",
    "                reference_image = clip_preprocess(plt.imread(reference_img_path))[None]\n",
    "                reference_image_features = clip_model.encode_image(reference_image)\n",
    "                similarity_scores = {}  # Store similarity scores for images\n",
    "\n",
    "                for img_path in matched_image_paths:\n",
    "                    if reference_img_path == img_path:\n",
    "                        continue\n",
    "                    target_image = clip_preprocess(plt.imread(img_path))[None]\n",
    "                    target_image_features = clip_model.encode_image(target_image)\n",
    "                    # Calculate similarity score using cosine similarity\n",
    "                    similarity_score = (1 + (target_image_features @ reference_image_features.T) / 2).item()\n",
    "\n",
    "                    similarity_scores[img_path] = similarity_score\n",
    "\n",
    "                # Sort the similarity scores and get top similar images\n",
    "                sorted_scores = dict(sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True))\n",
    "                top_similar_images = dict(itertools.islice(sorted_scores.items(), 3))\n",
    "\n",
    "                print(top_similar_images)\n",
    "                temp_counter = 1\n",
    "\n",
    "                for image_path in top_similar_images.keys():\n",
    "                    # Create new filename for copied similar images\n",
    "                    new_filename = f\"top{temp_counter}_crop.jpeg\"\n",
    "                    destination_path = os.path.join(root, new_filename)\n",
    "                    shutil.copy(image_path, destination_path)\n",
    "                    temp_counter += 1\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Error occurred during image comparison:\", e)\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Initialize YOLO model\n",
    "        yolo = YOLO(\"yolov8m.pt\")\n",
    "        input_directory = \"./All_Images\"\n",
    "        output_directory = \"output/problem5\"\n",
    "\n",
    "        # Call functions to perform object detection and image comparison\n",
    "        detect_and_save_objects(yolo, input_directory, output_directory)\n",
    "        compare_images_using_clip(clip, output_directory)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"An error occurred during execution:\", e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
